{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright\n",
    "\n",
    "<PRE>\n",
    "Jelen iTorch notebook a Budapesti Műszaki és Gazdaságtudományi Egyetemen tartott \"Deep Learning a gyakorlatban Python és LUA alapon\" tantárgy segédanyagaként készült. \n",
    "A tantárgy honlapja: http://smartlab.tmit.bme.hu/oktatas-deep-learning\n",
    "Deep Learning kutatás: http://smartlab.tmit.bme.hu/deep-learning\n",
    "Jelen notebook a hivatalos dokumentáció alapján készült: https://github.com/torch/torch7/blob/master/doc/tensor.md\n",
    "\n",
    "A notebook bármely részének újra felhasználása, publikálása csak a szerzők írásos beleegyezése esetén megegengedett.\n",
    "\n",
    "2016 (c) Császár Márk, Tóth Bálint Pál (toth.b kukac tmit pont bme pont hu)\n",
    "</PRE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bevezető"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az egyik legelterjedtebb Deep Learning keretrendszer, a Torch7 (http://torch.ch/) LUA nyelven készült. A LUA programnyelvet sokszor játékbotok készítésére is használják. Előnye, hogy nagyon gyorsan tanulható script nyelv, mely ANSI C-re épül és bináris kódra lehet fordítani, így viszonylag könnyű különböző platformokon történő integrációja (pl. Windows, Android).\n",
    "\n",
    "A Torch7-ben a Python nyelvhez kapcsolódó Numpy csomaghoz hasonló a Tensor (= mátrix = tömb) osztály. Ebben a notebookban ezek működését tekintjük röviden át. \n",
    "\n",
    "Ahhoz, hogy a Torch7-et használni tudjuk, a keretrendszer telepítése utána be kell töltenünk az alábbi módon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  deserialize : function: 0x41d25a38\n",
       "  cat : function: 0x40958e40\n",
       "  cdata : function: 0x40b98a38\n",
       "  newmetatable : function: 0x40ba29c8\n",
       "  atan2 : function: 0x410f38e0\n",
       "  log : function: 0x410f3548\n",
       "  zero : function: 0x40958558\n",
       "  logNormal : function: 0x4095adc8\n",
       "  sigmoid : function: 0x410f3840\n",
       "  getnumcores : function: 0x40ba26e8\n",
       "  cross : function: 0x40958c60\n",
       "  deserializeFromStorage : function: 0x41d35a40\n",
       "  inverse : function: 0x4095af08\n",
       "  updateerrorhandlers : function: 0x40b9a9f8\n",
       "  isTypeOf : function: 0x4095db30\n",
       "  ByteStorage : table: 0x40b93df8\n",
       "  prod : function: 0x40958b70\n",
       "  ger : function: 0x409589e0\n",
       "  eq : function: 0x40959070\n",
       "  getnumthreads : function: 0x40ba2698\n",
       "  ByteTensor : table: 0x410f07b0\n",
       "  Timer : table: 0x410f26a8\n",
       "  addmv : function: 0x40958a08\n",
       "  lerp : function: 0x410f38b8\n",
       "  match : function: 0x40958800\n",
       "  Allocator : table: 0x4095d598\n",
       "  xcorr2 : function: 0x40958f58\n",
       "  neg : function: 0x410f3868\n",
       "  histc : function: 0x410f3458\n",
       "  pstrf : function: 0x4095afa8\n",
       "  bernoulli : function: 0x40958eb8\n",
       "  MemoryFile : table: 0x410f8480\n",
       "  cremainder : function: 0x409588c8\n",
       "  Storage : table: 0x410efa30\n",
       "  ge : function: 0x40959048\n",
       "  kthvalue : function: 0x40958d78\n",
       "  geometric : function: 0x40958e90\n",
       "  sin : function: 0x410f3638\n",
       "  topk : function: 0x40958d50\n",
       "  baddbmm : function: 0x40958aa8\n",
       "  fill : function: 0x40958580\n",
       "  linspace : function: 0x410f34f8\n",
       "  sum : function: 0x40958b48\n",
       "  numel : function: 0x40958ad0\n",
       "  orgqr : function: 0x4095b020\n",
       "  test : function: 0x40d45658\n",
       "  cmul : function: 0x40958828\n",
       "  _heaptracking : true\n",
       "  getconstructortable : function: 0x40ba2738\n",
       "  version : function: 0x40ba16a8\n",
       "  fmod : function: 0x40958760\n",
       "  FloatTensor : table: 0x410f66b8\n",
       "  mean : function: 0x410f33e0\n",
       "  isTensor : function: 0x40d456c0\n",
       "  ShortStorage : table: 0x40baf0e0\n",
       "  cmin : function: 0x40958be8\n",
       "  addcdiv : function: 0x40958940\n",
       "  mm : function: 0x40958990\n",
       "  Tester : table: 0x40bad528\n",
       "  xcorr3 : function: 0x40958fa8\n",
       "  ShortTensor : table: 0x410f2d80\n",
       "  lt : function: 0x40958fd0\n",
       "  triu : function: 0x40958e18\n",
       "  repeatTensor : function: 0x4096a150\n",
       "  data : function: 0x40b989f8\n",
       "  CmdLine : table: 0x419f59f8\n",
       "  eye : function: 0x40958cb0\n",
       "  loadobj : function: 0x41d2ced8\n",
       "  mul : function: 0x40958710\n",
       "  sqrt : function: 0x410f3728\n",
       "  LongTensor : table: 0x410f54a8\n",
       "  saveobj : function: 0x419f5788\n",
       "  trunc : function: 0x410f37c8\n",
       "  isequal : function: 0x40ba2930\n",
       "  floor : function: 0x410f37a0\n",
       "  serialize : function: 0x41d25e50\n",
       "  load : function: 0x41d2ced8\n",
       "  save : function: 0x419f5788\n",
       "  permute : function: 0x40ba82b0\n",
       "  totable : function: 0x40d456a0\n",
       "  csub : function: 0x409586e8\n",
       "  gesv : function: 0x4095ae18\n",
       "  PipeFile : table: 0x410f6028\n",
       "  LongStorage : table: 0x410edc58\n",
       "  chunk : function: 0x4096aa88\n",
       "  split : function: 0x4096aa68\n",
       "  Tensor : table: 0x410f7898\n",
       "  diag : function: 0x40958c88\n",
       "  std : function: 0x410f3430\n",
       "  viewAs : function: 0x4096aa48\n",
       "  view : function: 0x4096aa08\n",
       "  conv3 : function: 0x40958f80\n",
       "  expandAs : function: 0x4096a130\n",
       "  File : table: 0x40b921e8\n",
       "  expand : function: 0x40968ff0\n",
       "  uniform : function: 0x4095ad50\n",
       "  all : function: 0x410f3368\n",
       "  renorm : function: 0x410f34a8\n",
       "  rsqrt : function: 0x410f3818\n",
       "  typename : function: 0x40ba28e8\n",
       "  scatter : function: 0x40958648\n",
       "  setdefaulttensortype : function: 0x4095daf0\n",
       "  addbmm : function: 0x40958a80\n",
       "  class : function: 0x4095dad0\n",
       "  symeig : function: 0x4095ae90\n",
       "  remainder : function: 0x40958788\n",
       "  clamp : function: 0x409587d8\n",
       "  getmetatable : function: 0x40ba2a18\n",
       "  packageLuaPath : function: 0x4095d5e8\n",
       "  updatethreadlocals : function: 0x4095d698\n",
       "  metatype : function: 0x40ba2a40\n",
       "  setRNGState : function: 0x4095b3b8\n",
       "  getRNGState : function: 0x4095b2b0\n",
       "  manualSeed : function: 0x4095b260\n",
       "  initialSeed : function: 0x4095b210\n",
       "  zeros : function: 0x409585a8\n",
       "  median : function: 0x40958dc8\n",
       "  cosh : function: 0x410f3610\n",
       "  pushudata : function: 0x40ba1680\n",
       "  geqrf : function: 0x4095aff8\n",
       "  _gen : torch.Generator\n",
       "  Generator : table: 0x4095b6d0\n",
       "  ormqr : function: 0x4095b048\n",
       "  FloatStorage : table: 0x410ee028\n",
       "  seed : function: 0x4095b798\n",
       "  qr : function: 0x4095afd0\n",
       "  reshape : fun"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ction: 0x409585f8\n",
       "  potrs : function: 0x4095af58\n",
       "  cpow : function: 0x40958850\n",
       "  abs : function: 0x410f33b8\n",
       "  dist : function: 0x410f34d0\n",
       "  svd : function: 0x4095aee0\n",
       "  mod : function: 0x409587b0\n",
       "  eig : function: 0x4095aeb8\n",
       "  IntTensor : table: 0x410f4298\n",
       "  cdiv : function: 0x40958878\n",
       "  pow : function: 0x410f3908\n",
       "  gt : function: 0x40958ff8\n",
       "  randperm : function: 0x40958d00\n",
       "  include : function: 0x4095dab0\n",
       "  exponential : function: 0x4095adf0\n",
       "  atan : function: 0x410f36d8\n",
       "  nonzero : function: 0x409590c0\n",
       "  normal : function: 0x4095ad78\n",
       "  multinomial : function: 0x4095ad28\n",
       "  randn : function: 0x4095ad00\n",
       "  any : function: 0x410f3390\n",
       "  equal : function: 0x40958698\n",
       "  dot : function: 0x40958670\n",
       "  range : function: 0x40958cd8\n",
       "  rand : function: 0x410f3930\n",
       "  addr : function: 0x40958a58\n",
       "  trtrs : function: 0x4095ae68\n",
       "  cinv : function: 0x410f3890\n",
       "  tan : function: 0x410f36b0\n",
       "  frac : function: 0x410f37f0\n",
       "  serializeToStorage : function: 0x41d2aae8\n",
       "  ceil : function: 0x410f3778\n",
       "  squeeze : function: 0x40958ee0\n",
       "  var : function: 0x410f3408\n",
       "  tanh : function: 0x410f3700\n",
       "  setmetatable : function: 0x40ba29f0\n",
       "  cumsum : function: 0x40958af8\n",
       "  cauchy : function: 0x4095ada0\n",
       "  ne : function: 0x40959098\n",
       "  sinh : function: 0x410f3688\n",
       "  cos : function: 0x410f35c0\n",
       "  potrf : function: 0x4095af30\n",
       "  DoubleStorage : table: 0x410efa30\n",
       "  CharStorage : table: 0x40b92370\n",
       "  asin : function: 0x410f3660\n",
       "  exp : function: 0x410f3598\n",
       "  log1p : function: 0x410f3570\n",
       "  pointer : function: 0x40b9b300\n",
       "  addcmul : function: 0x40958918\n",
       "  add : function: 0x409586c0\n",
       "  type : function: 0x4095db10\n",
       "  sign : function: 0x40958f08\n",
       "  div : function: 0x40958738\n",
       "  mode : function: 0x40958da0\n",
       "  toc : function: 0x419f9a88\n",
       "  norm : function: 0x410f3480\n",
       "  gather : function: 0x40958620\n",
       "  tic : function: 0x40b97500\n",
       "  gels : function: 0x4095ae40\n",
       "  mv : function: 0x40958968\n",
       "  getdefaulttensortype : function: 0x419f9a60\n",
       "  isStorage : function: 0x40d456e0\n",
       "  logspace : function: 0x410f3520\n",
       "  factory : function: 0x40ba2710\n",
       "  CharTensor : table: 0x410f1b70\n",
       "  setnumthreads : function: 0x40b9b2d8\n",
       "  IntStorage : table: 0x40bafe88\n",
       "  TestSuite : function: 0x4097e0a8\n",
       "  cumprod : function: 0x40958b20\n",
       "  potri : function: 0x4095af80\n",
       "  le : function: 0x40959020\n",
       "  setenv : function: 0x40ba29a0\n",
       "  tril : function: 0x40958df0\n",
       "  getenv : function: 0x40ba2958\n",
       "  acos : function: 0x410f35e8\n",
       "  addmm : function: 0x40958a30\n",
       "  isatty : function: 0x419f9ac0\n",
       "  min : function: 0x40958b98\n",
       "  max : function: 0x40958bc0\n",
       "  cmax : function: 0x40958c10\n",
       "  DoubleTensor : table: 0x410f7898\n",
       "  sort : function: 0x40958d28\n",
       "  trace : function: 0x40958c38\n",
       "  ones : function: 0x409585d0\n",
       "  cfmod : function: 0x409588a0\n",
       "  round : function: 0x410f3750\n",
       "  bmm : function: 0x409589b8\n",
       "  DiskFile : table: 0x410f4dc8\n",
       "  conv2 : function: 0x40958f30\n",
       "  setheaptracking : function: 0x40b9b328\n",
       "  cmod : function: 0x409588f0\n",
       "  random : function: 0x40958e68\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Többdimenziós-mátrixok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tensor osztály tagjai legtöbb esetben többdimenziós-mátrixok. Gépi tanulás szempontjából fontosabb mátrixtípusok: \n",
    "    \n",
    "    ByteTensor (képek RGB csatornái), \n",
    "    \n",
    "    FloatTensor (általános adat CPU-n), \n",
    "    \n",
    "    CudaTensor (adat GPU-n)\n",
    "\n",
    "A mátrix dimenzióinak száma korlátlanul megadható, azonban a dimenziószám alapján két csoportként kezeljük őket. 4 dimenzióig mátrixokat létrehozhatunk a torch.Tensor() paranccsal. Példaként, ez egy 4x5x6x2-es mátrix lesz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = torch.Tensor(4,5,6,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amennyiben több dimenzióra lenne szükségünk, akkor a létrehozás a torch.Longstorage() paranccsal történik. Gyakorlatban erre ritkán van szükségünk. Például az alábbi módon hozhatunk létre egy hat dimenziós mátrix adatainak tárolására alkalmas tárolót, ahol dimenziónként tudjuk a mátrix méreteit megadni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = torch.LongStorage(6)\n",
    "s[1] = 4; s[2] = 5; s[3] = 6; s[4] = 2; s[5] = 7; s[6] = 3;\n",
    "x = torch.Tensor(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A létrehozott mátrixokról különböző hasznos információkat tudhatunk meg, ha az alábbi parancsok valamelyikét futtatjuk. Elsőként tekintsük a mátrix méretét az egyes dimenziók mentén, amelyet lekérdezhetünk a \"#\" karakter mátrix változója elé való írásával, ami ekvivalens a size() paranccsal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 5\n",
       " 6\n",
       " 2\n",
       " 7\n",
       " 3\n",
       "[torch.LongStorage of size 6]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 5\n",
       " 6\n",
       " 2\n",
       " 7\n",
       " 3\n",
       "[torch.LongStorage of size 6]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x:size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha csak egy dimenzió (például az elsőre) méretére vagyunk kíváncsiak, akkor azt az alábbi módon tehetjük meg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x:size(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amennyiben szeretnénk lekérdezni egy mátrix dimenziószámát, akkor azt megtehetjük a nDimension() vagy dim() parancsokkal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6\t\n",
       "6\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x:nDimension())\n",
    "print(x:dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adatok belső reprezentációja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mátrixok valódi adatait (értékeit) egy úgynevezett Storage tárolja, amelyet elérhetünk a storage() paranccsal.\n",
    "Habár a mátrix adatait ez a bizonyos Storage tárolja, a memóriában nem feltétlenül folytonosan kerül foglalásra.\n",
    "A mátrix első pontját storageOffset() paranccsal érhetjük el (1-től kezdődik). Ha szeretnénk elérni egy másik \n",
    "elemet az i-edik dimenzióban, akkor a stride(i) parancs alkalmas erre. Tekintsük az alábbi 3 dimenziós tömböt, melynek a (3,4,5) elemét az alábbi módszerrel érhetjük el:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(7,7,7)\n",
    "print(x[3][4][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mondhatjuk azt is, hogy a Tensor gyakorlatilag úgy működik mint egy szemüveg; A Storage szolgál arra, hogy tároljuk az adatokat, a Tensor pedig ezeket az adatokat rendezi dimenziók szerint. Hozzunk létre egy 4x5-ös mátrixot és a hozzá tartozó Storage-ot és töltsük fel ezt adatokkal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.Tensor(4,5)\n",
    "s = x:storage()\n",
    "for i=1,s:size() do\n",
    "  s[i] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezt követően a Tensor-ban is megjelennek az adatok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1   2   3   4   5\n",
       "  6   7   8   9  10\n",
       " 11  12  13  14  15\n",
       " 16  17  18  19  20\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Természetesen közvetlenül a Tensor-t is feltölthetjük adatokkal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10  11  12  13  14\n",
       " 15  16  17  18  19\n",
       " 20  21  22  23  24\n",
       " 25  26  27  28  29\n",
       "[torch.DoubleTensor of size 4x5]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "for i=1, x:size(1) do\n",
    "    for j=1, x:size(2) do\n",
    "        x[i][j] = k\n",
    "        k = k + 1 \n",
    "    end\n",
    "end\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Érdemes megjegyezni, hogy habár a teljes mátrix nem folytonosan helyezkedik el a memóriában, a mátrix egy sora (az utolsó dimenzió mentén) azonban igen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hatékony memória-kezelés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tensor-okon végzett műveletek közül egyik sem másol memóriatartalmat. Mindegyik a művelet vagy egy meglévőt Tensor-t alakít át vagy egy új Tensort hoz létre, amely egy meglévő Storage-re mutat. Ha azonban mégis másolásra lenne szükségünk, akkor megtehetjük azt a copy() vagy clone() paranccsal. A gyakorlatban az utóbbit szoktuk használni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = torch.Tensor(x:size()):copy(x)\n",
    "y2 = x:clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mátrix-konstruktorok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Tensor konstruktorok új Tensor objektumokat hoznak létre, opcionálisan újabb memóriaterületet lefoglalva. Alapesetben az újnonnan allokált memória nem kerül inicializálásra. A továbbiakban az alábbi példákon szemléltetjük, hogyan lehet inicializálni egy Tensort.\n",
    "\n",
    "Egy üres Tensor létrehozása:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.DoubleTensor with no dimension]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az új Tensor is \"látni\" fogja ugyanazt Stroage-t, amelyet a paraméterként megadott Tensor is lát. Ennek eredménye, hogy az új Tensoron végzett műveletek hatással lesznek az eredeti Tensorra is és vice-versa. Nincs memóriamásolás.\n",
    "\n",
    "2x5-ös mátrix létrehozása és feltöltése 3.14-es értékekkel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.1400  3.1400  3.1400  3.1400  3.1400\n",
       " 3.1400  3.1400  3.1400  3.1400  3.1400\n",
       "[torch.DoubleTensor of size 2x5]\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(2,5):fill(3.14)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"y\" mátrix legyen egyenlő \"x\"-szel, majd \"y\" elemeinek kinullázása után az \"x\" elemei is kinullázódnak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       "[torch.DoubleTensor of size 2x5]\n",
       "\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.Tensor(x)\n",
    "y:zero()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha clone()-ozzuk, akkor nem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0\n",
       " 0  0  0  0  0\n",
       "[torch.DoubleTensor of size 2x5]\n",
       "\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x:clone()\n",
    "y:zero()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mátrixot az alábbi módon tudunk létrehozni tetszőleges adatokkal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  2  3  4\n",
       " 5  6  7  8\n",
       "[torch.DoubleTensor of size 2x4]\n",
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor({{1,2,3,4}, {5,6,7,8}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kódírás és debuggolás közben van, hogy szükségünk van 1-1 Tensor típusának kiolvasására, ezt így tudjuk megtenni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.DoubleTensor\t\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(x):type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adódhat olyan helyzet, amikor szeretnénk egy Tensor adatait átkasztolni. Ezt könnyen megtehetjük az alábbi módok egyikével:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.1400\n",
       " 3.1400\n",
       " 3.1400\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(3):fill(3.14)\n",
    "print(x)\n",
    "x:type('torch.IntTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.1400\n",
       " 3.1400\n",
       " 3.1400\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(3):fill(3.14)\n",
    "print(x)\n",
    "x:int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorok szerkezete és elemei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A korábbiakban bemutatott nDimension(), dim(), storage() illetve size() függvények mellett hasznosak a következőek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lehetőségünk van összehasonlítani két Tensort méretük alapján a isSameSizeAs() függvény meghívásával. Legyen x és y 4x5-ös méretű Tensorok: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\t\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(4,5)\n",
    "y = torch.Tensor(4,5)\n",
    "print(x:isSameSizeAs(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rendelkezzen y ezúttal 4x6-os mérettel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false\t\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.Tensor(4,6)\n",
    "print(x:isSameSizeAs(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x Tensor elemszámának meghatározása egyszerű:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20\t\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x:nElement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexálás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LUA-ban az egyik legnehezebb megszokni, hogy az indexálást minden esetben 1-től kezdi. (Szemben pl. Numpy-val, ahol 0 jelöli az első elemet.)\n",
    "\n",
    "Legyen \"x\" egy 3x3-as méretű Tensor és töltsük fel egyre növekvő értékkel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  2  3\n",
       " 4  5  6\n",
       " 7  8  9\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(3,3)\n",
    "i = 0; x:apply(function() i = i + 1; return i end)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Először válasszuk ki a második sort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       " 5\n",
       " 6\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majd a második oszlopot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2\n",
       " 5\n",
       " 8\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[{{},2}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "És a második sor, harmadik elemét két féle képp is kiválaszthatjuk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6\t\n",
       "6\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[2][3])\n",
    "print(x[{2,3}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor inicializálás és másolás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Négy elemű tömb létrehozása és feltöltése csupa nullával:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(4):zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amely ekvivalens, a fill() függvény megfelelő használatával:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.IntTensor of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.IntTensor(4):fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A korábbiakban már említett copy() parancs átmásolja egy új Tensorba a paraméterként megadott Tensor elemeit. Az elemszámnak egyeznie kell, méreteknek azonban nem szükséges.\n",
    "\n",
    "Négy elemből (csupa egyes) álló Tensor létrehozása:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.DoubleTensor of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(4):fill(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Másoljuk át \"x\" Tensor-t \"y\"-ba, ahol \"y\" alakja már 2x2-es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  1\n",
       " 1  1\n",
       "[torch.DoubleTensor of size 2x2]\n",
       "\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.Tensor(2,2):copy(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorok részegységeinek módosítása"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tekintsünk egy 5x6-os, csupa nullákból álló mátrixot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 5x6]\n",
       "\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5, 6):zero()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jelöljük ki a 2 és a (2+3-1) közötti elemeket az első dimenzió (sorok) mentén és adjunk nekik 1 értéket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = x:narrow(1, 2, 3)\n",
    "y:fill(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vegyük észre, hogy x Tensor elemei is módosultak. Nem történt memóriamásolás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0  0\n",
       " 1  1  1  1  1  1\n",
       " 1  1  1  1  1  1\n",
       " 1  1  1  1  1  1\n",
       " 0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 5x6]\n",
       "\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensor \"szemüvegének\" (view) módosítása"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Négy elemből álló Tensor létrehozása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.zeros(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A view() segítségével könnyen 3x3-es nézetben tudjuk vizsgálni x elemeit (és 3x3-as tömbként tudunk vele dolgozni):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0\n",
       " 0  0  0\n",
       " 0  0  0\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x:view(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legyen \"x\" egy 3x4-es, csupa nullákból álló Tensor és a harmadik oszlop elemeinek adjunk 7-es értéket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.DoubleTensor of size 3x4]\n",
       "\n",
       " 0  0  7  0\n",
       " 0  0  7  0\n",
       " 0  0  7  0\n",
       "[torch.DoubleTensor of size 3x4]\n",
       "\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(3,4):zero()\n",
    "print(x)\n",
    "x:select(2,3):fill(7)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezt a következő képpen is megtehetjük (csak a szemléltethetőség miatt szerepelnek négyes értékek):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  4  0\n",
       " 0  0  4  0\n",
       " 0  0  4  0\n",
       "[torch.DoubleTensor of size 3x4]\n",
       "\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[{{},3}] = 4\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cseréljük meg az első és második dimenziót. A transpose() helyett használható a rövidebb t() verzió is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  0\n",
       " 0  0  0\n",
       " 4  4  4\n",
       " 0  0  0\n",
       "[torch.DoubleTensor of size 4x3]\n",
       "\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x:transpose(1,2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jelöljük ki az így létrehozott Tensor harmadik oszlopát, és adjunk az elemeinek 8-as értéket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  8\n",
       " 0  0  8\n",
       " 4  4  8\n",
       " 0  0  8\n",
       "[torch.DoubleTensor of size 4x3]\n",
       "\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y:select(2, 3):fill(8)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ezzel párhuzamosan x Tensor is megváltozott. Nem történt memóriamásolás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0  0  4  0\n",
       " 0  0  4  0\n",
       " 8  8  8  8\n",
       "[torch.DoubleTensor of size 3x4]\n",
       "\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Függvények alkalmazása Tensorokon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az alábbi módszerek segítségével egy Tensor összes elemére tudunk alkalmazni bizonyos függvényeket, gyorsabban és kompaktabb módon, mintha ciklust használnánk az iterációk során.\n",
    "\n",
    "Legyen z egy 3x3-as méretű mátrix és töltsük fel értékekkel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1  2  3\n",
       " 4  5  6\n",
       " 7  8  9\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.Tensor(3,3)\n",
    "i = 0\n",
    "z:apply(function(x)\n",
    "  i = i + 1\n",
    "  return i\n",
    "end)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezután vegyük a \"z\" elemeinek szinuszát:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.8415  0.9093  0.1411\n",
       "-0.7568 -0.9589 -0.2794\n",
       " 0.6570  0.9894  0.4121\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z:apply(math.sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majd összegét:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9552094821074\t\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "z:apply(function(x)\n",
    "  sum = sum + x\n",
    "end)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amely természetesen megegyezik a beépített függvény által kapott értékkel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9552094821074\t\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z:sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorok mozgatása GPU-ra és GPU-ról"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mély tanulás során általában GPU-t használunnk a számításokhoz. Torch7 alatt igen egyszerű a Tensorok GPU-ra való mozgatása. Ehhez előbb be kell húznunk a cutorch-ot (CUDA Torch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  getPeerToPeerAccess : function: 0x40f3fd40\n",
       "  getStream : function: 0x40f3fa10\n",
       "  getDeviceCount : function: 0x40f3fce8\n",
       "  setHeapTracking : function: 0x40f40540\n",
       "  manualSeedAll : function: 0x40f3f950\n",
       "  getRNGState : function: 0x40f3f978\n",
       "  setKernelPeerToPeerAccess : function: 0x40f3fdf8\n",
       "  reserveBlasHandles : function: 0x40f3e608\n",
       "  setDefaultStream : function: 0x40f3fa68\n",
       "  getMemoryUsage : function: 0x40f3f6d8\n",
       "  streamBarrier : function: 0x40f3fb68\n",
       "  manualSeed : function: 0x40f3f900\n",
       "  driverVersion : 8000\n",
       "  synchronize : function: 0x40f3ef90\n",
       "  reserveStreams : function: 0x40f3f798\n",
       "  getDevice : function: 0x40f3fc48\n",
       "  seed : function: 0x40f3f888\n",
       "  getBlasHandle : function: 0x40f3f748\n",
       "  withDevice : function: 0x4112f400\n",
       "  deviceReset : function: 0x40f3fc98\n",
       "  Event : table: 0x40d55078\n",
       "  test : function: 0x4112f378\n",
       "  _stategc : userdata: 0x419f3820\n",
       "  getNumStreams : function: 0x40f3f7e8\n",
       "  streamWaitFor : function: 0x40f3fab8\n",
       "  synchronizeAll : function: 0x40f3e5b0\n",
       "  initialSeed : function: 0x40f3f8d8\n",
       "  getDeviceProperties : function: 0x40f3f688\n",
       "  CudaHostAllocator : torch.Allocator\n",
       "  getNumBlasHandles : function: 0x40f3e800\n",
       "  getState : function: 0x40f40518\n",
       "  setStream : function: 0x40f3f838\n",
       "  getKernelPeerToPeerAccess : function: 0x40f3e7d0\n",
       "  setRNGState : function: 0x40f3f9a0\n",
       "  createCudaHostTensor : function: 0x4112f440\n",
       "  streamWaitForMultiDevice : function: 0x40f3fb18\n",
       "  streamSynchronize : function: 0x40f3fc20\n",
       "  seedAll : function: 0x40f3f8b0\n",
       "  setDevice : function: 0x40f3f860\n",
       "  setPeerToPeerAccess : function: 0x40f3fd98\n",
       "  hasHalf : true\n",
       "  streamBarrierMultiDevice : function: 0x40f3fbc8\n",
       "  setBlasHandle : function: 0x40f3f630\n",
       "  _state : userdata: 0x01a85850\n",
       "}\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'cutorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezen túl még a cunn könyvtárat fogjuk sokszor használni, de arra még nincs szükségünk egyelőre. \n",
    "\n",
    "Hozzunk létre két Tensor-t, adjuk össze 1000-szer és nézzük meg, hogy mennyi időbe telik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0000000000\t\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1=torch.rand(5000,5000)\n",
    "m2=torch.rand(5000,5000) \n",
    "\n",
    "startt=os.time()\n",
    "for i=1,1000 do\n",
    "   C = torch.add(m1, m2)\n",
    "end\n",
    "endt=os.time()\n",
    "elapsed=os.difftime(endt,startt)\n",
    "print(\"%.10f\" % elapsed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most vigyük át a GPU-ra a két Tensor-t és végezzük el ugyanezt a számítást:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000\t\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1=m1:cuda()\n",
    "m2=m2:cuda()\n",
    "\n",
    "startt=os.time()\n",
    "for i=1,1000 do\n",
    "   C = torch.add(m1, m2)\n",
    "end\n",
    "endt=os.time()\n",
    "elapsed=os.difftime(endt,startt)\n",
    "print(\"%.10f\" % elapsed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Végül pedig vigyük vissza a CPU-ra, és számoljuk ki még egyszer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0000000000\t\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1=m1:float()\n",
    "m2=m2:float()\n",
    "\n",
    "startt=os.time()\n",
    "for i=1,1000 do\n",
    "   C = torch.add(m1, m2)\n",
    "end\n",
    "endt=os.time()\n",
    "elapsed=os.difftime(endt,startt)\n",
    "print(\"%.10f\" % elapsed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nagyon fontos, hogy figyelnünk kell arra, hogy a lehető legkevesebb CPU <-> GPU közötti memóriaművelet legyen, mert az jelentősen rontja a számítási kapacitást. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
