{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright\n",
    "\n",
    "<PRE>\n",
    "Jelen iPython notebook a Budapesti Műszaki és Gazdaságtudományi Egyetemen tartott \"Deep Learning a gyakorlatban Python és LUA alapon\" tantárgy segédanyagaként készült. \n",
    "A tantárgy honlapja: http://smartlab.tmit.bme.hu/oktatas-deep-learning\n",
    "Deep Learning kutatás: http://smartlab.tmit.bme.hu/deep-learning\n",
    "\n",
    "A notebook bármely részének újra felhasználása, publikálása csak a szerzők írásos beleegyezése esetén megegengedett.\n",
    "\n",
    "2016 (c) Tóth Bálint Pál (toth.b kukac tmit pont bme pont hu)\n",
    "</PRE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR TensorFlow alapon\n",
    "Az alábbiakban a XOR problémát oldjuk meg TensorFlow alapon. A többi megoldáshoz képest láthatjuk az előnyöket, hátrányokat. Az egyszerűség kedvéért kommentekben jelöljük az egyes sorok jelentését."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step:   0\n",
      "loss: 0.31454208493232727\n",
      "\n",
      "step: 200\n",
      "loss: 0.21070915460586548\n",
      "\n",
      "step: 400\n",
      "loss: 0.12810538709163666\n",
      "\n",
      "step: 600\n",
      "loss: 0.050660908222198486\n",
      "\n",
      "step: 800\n",
      "loss: 0.022156227380037308\n",
      "\n",
      "step: 1000\n",
      "loss: 0.012298425659537315\n",
      "\n",
      "step: 1200\n",
      "loss: 0.008005021139979362\n",
      "\n",
      "step: 1400\n",
      "loss: 0.005752319935709238\n",
      "\n",
      "step: 1600\n",
      "loss: 0.004409763030707836\n",
      "\n",
      "step: 1800\n",
      "loss: 0.003535374067723751\n",
      "\n",
      "step: 2000\n",
      "loss: 0.0029280935414135456\n",
      "\n",
      "step: 2200\n",
      "loss: 0.0024854433722794056\n",
      "\n",
      "step: 2400\n",
      "loss: 0.0021504689939320087\n",
      "\n",
      "input: [0.0, 0.0] | output: [[ 0.0410834]]\n",
      "input: [0.0, 1.0] | output: [[ 0.95252711]]\n",
      "input: [1.0, 0.0] | output: [[ 0.95943624]]\n",
      "input: [1.0, 1.0] | output: [[ 0.04956487]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf    \n",
    "\n",
    "# Tanító (bemeneti és kimeneti) adatok definiálása\n",
    "input_data = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]  \n",
    "output_data = [[0.], [1.], [1.], [0.]]\n",
    "\n",
    "# a bemenet és kimenet definiálása\n",
    "n_input = tf.placeholder(tf.float32, shape=[None, 2], name=\"n_input\")\n",
    "n_output = tf.placeholder(tf.float32, shape=[None, 1], name=\"n_output\")\n",
    "\n",
    "# a rejtett réteg beli neuronok száma paraméterként\n",
    "hidden_neurons = 10\n",
    "\n",
    "# bias definiálása (+1 bemenet)\n",
    "b_hidden = tf.Variable(tf.random_normal([hidden_neurons]), name=\"hidden_bias\")\n",
    "# bemenet - rejtett réteg közötti súlyok definiálása\n",
    "W_hidden = tf.Variable(tf.random_normal([2, hidden_neurons]), name=\"hidden_weights\")\n",
    "# rejtett réteg beli aktivációs függvény\n",
    "hidden = tf.sigmoid(tf.matmul(n_input, W_hidden) + b_hidden)\n",
    "\n",
    "# rejtett réteg - kimenet közötti súlyok definiálása\n",
    "W_output = tf.Variable(tf.random_normal([hidden_neurons, 1]), name=\"output_weights\")  \n",
    "# kimeneti réteg aktivációs függvény\n",
    "output = tf.sigmoid(tf.matmul(hidden, W_output))  \n",
    "\n",
    "# költség függvény definiálása\n",
    "cost = tf.reduce_mean(tf.square(n_output-output)) \n",
    "# Gradiens descent-et használunk 0.5-ös tanulási rátával\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "# A költségfüggvény minimalizálása a cél\n",
    "train = optimizer.minimize(cost)  \n",
    "\n",
    "# Az összes változó inicializálásához szükség \n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Új session és egyúttal gráf elkészítése\n",
    "sess = tf.Session()  \n",
    "# A változók inicializálása\n",
    "sess.run(init)\n",
    "\n",
    "# 2500 epochig futtatjuk\n",
    "for epoch in range(0, 2501):\n",
    "    # a tanítás futtatása\n",
    "    cvalues = sess.run([train, cost, W_hidden, b_hidden, W_output],\n",
    "                       feed_dict={n_input: input_data, n_output: output_data})\n",
    "\n",
    "    # és az eredmények megjelenítése 200 epoch-onként\n",
    "    if epoch % 200 == 0:\n",
    "        print(\"\")\n",
    "        print(\"step: {:>3}\".format(epoch))\n",
    "        print(\"loss: {}\".format(cvalues[1]))\n",
    "\n",
    "# tanítás végén a tanítás eredményeinek kiiratása\n",
    "print(\"\")\n",
    "for i in range (0,4):\n",
    "    print(\"input: {} | output: {}\".format(input_data[i], sess.run(output, feed_dict={n_input: [input_data[i]]})))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vagy \"röviden\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step:   0\n",
      "loss: 0.3331732153892517\n",
      "\n",
      "step: 200\n",
      "loss: 0.1920488178730011\n",
      "\n",
      "step: 400\n",
      "loss: 0.09497947245836258\n",
      "\n",
      "step: 600\n",
      "loss: 0.03884473815560341\n",
      "\n",
      "step: 800\n",
      "loss: 0.01968100666999817\n",
      "\n",
      "step: 1000\n",
      "loss: 0.012102765031158924\n",
      "\n",
      "step: 1200\n",
      "loss: 0.008404145017266273\n",
      "\n",
      "step: 1400\n",
      "loss: 0.006305226124823093\n",
      "\n",
      "step: 1600\n",
      "loss: 0.004983656108379364\n",
      "\n",
      "step: 1800\n",
      "loss: 0.004087673965841532\n",
      "\n",
      "step: 2000\n",
      "loss: 0.0034460846800357103\n",
      "\n",
      "step: 2200\n",
      "loss: 0.002967043314129114\n",
      "\n",
      "step: 2400\n",
      "loss: 0.002597430720925331\n",
      "\n",
      "input: [0.0, 0.0] | output: [[ 0.04432632]]\n",
      "input: [0.0, 1.0] | output: [[ 0.95356733]]\n",
      "input: [1.0, 0.0] | output: [[ 0.94757903]]\n",
      "input: [1.0, 1.0] | output: [[ 0.05382513]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf    \n",
    "\n",
    "input_data = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]  \n",
    "output_data = [[0.], [1.], [1.], [0.]]\n",
    "\n",
    "n_input = tf.placeholder(tf.float32, shape=[None, 2], name=\"n_input\")\n",
    "n_output = tf.placeholder(tf.float32, shape=[None, 1], name=\"n_output\")\n",
    "\n",
    "hidden_neurons = 10\n",
    "\n",
    "b_hidden = tf.Variable(tf.random_normal([hidden_neurons]), name=\"hidden_bias\")\n",
    "W_hidden = tf.Variable(tf.random_normal([2, hidden_neurons]), name=\"hidden_weights\")\n",
    "hidden = tf.sigmoid(tf.matmul(n_input, W_hidden) + b_hidden)\n",
    "W_output = tf.Variable(tf.random_normal([hidden_neurons, 1]), name=\"output_weights\")  \n",
    "output = tf.sigmoid(tf.matmul(hidden, W_output))  \n",
    "\n",
    "cost = tf.reduce_mean(tf.square(n_output-output)) \n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(cost)  \n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()  \n",
    "sess.run(init)\n",
    "for epoch in range(0, 2501):\n",
    "    cvalues = sess.run([train, cost, W_hidden, b_hidden, W_output],\n",
    "                       feed_dict={n_input: input_data, n_output: output_data})\n",
    "    if epoch % 200 == 0:\n",
    "        print(\"\")\n",
    "        print(\"step: {:>3}\".format(epoch))\n",
    "        print(\"loss: {}\".format(cvalues[1]))\n",
    "\n",
    "print(\"\")\n",
    "for i in range (0,4):\n",
    "    print(\"input: {} | output: {}\".format(input_data[i], sess.run(output, feed_dict={n_input: [input_data[i]]})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
